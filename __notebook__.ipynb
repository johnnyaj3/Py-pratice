{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "7c8efaff-a9e4-603d-b06b-afb5cda9b360"
   },
   "source": [
    "# Titanic Machine Learning\n",
    "### Tony Reina\n",
    "### Last update: 12 Oct 2016\n",
    "#### Here's the Titanic machine learning dataset from [Kaggle](https://www.kaggle.com/c/titanic). I'm analyzing it using Scikit-Learn's Adaptive Boost [adaboost](http://scikit-learn.org/stable/modules/ensemble.html#adaboost).\n",
    "\n",
    "The Titanic dataset is a good set to start learning data science. It's small enough to work through in a single day (or two). It has mixed data types (numeric and non-numeric). It has missing values and errorneous data to handle. And-- even with the simplest of data analysis techniques-- you can get a prediction accuracy greater than 70% without a lot of effort.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "f53260fa-8645-0a07-05c4-48f3041cdb41"
   },
   "source": [
    "## Import the python libraries\n",
    "\n",
    "First, we just need to import the Python libraries for loading and pre-processing datasets ([pandas](http://pandas.pydata.org/), [numpy](http://numpy.org)) and plotting data ([matplotlib](http://matplotlib.org) and [seaborn](https://pypi.python.org/pypi/seaborn)). Strictly speaking, you don't need the plotting stuff to run the code; however, good analysis demands that we visually inspect the data before we run it through models. The better we can pre-process the data (i.e. determine possible trends, identify possibly significant variables, remove/handle missing values), the better our model will be."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "7ef454b8-bd4c-960d-e775-bc51588788de"
   },
   "outputs": [],
   "source": [
    "import pandas as pd              # pandas is great for managing datasets as a single object\n",
    "import numpy as np               # numpy has great matrix/math operations on arrays\n",
    "\n",
    "import matplotlib.pyplot as plt  # allows you to print figures and charts\n",
    "import seaborn as sns            # a fancy chart add-on for matplotlib\n",
    "\n",
    "# This command creates the figures and charts within the Jupyter notebook\n",
    "%matplotlib inline     "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "a9ebdcd1-8222-30bc-3d52-a5bcb3eff3b7"
   },
   "source": [
    "## Pre-processing functions\n",
    "These functions are used to pre-process the data (which is stored in a Pandas dataframe, `df`). According to the [Kaggle website](https://www.kaggle.com/c/titanic/data), the data looks like this:\n",
    "\n",
    "| Variable Name  | Description                        | Type |\n",
    "| -------------- | ---------------------------------- | ---- |\n",
    "| survival       | Survival  (**Our model tries to predict this based on the other variables.**)                         | number  |\n",
    "|                | Values: (0 = No; 1 = Yes)                  | \n",
    "| pclass         | Passenger Class                    | number  |\n",
    "|                | Values: (1 = 1st; 2 = 2nd; 3 = 3rd)  |\n",
    "| name           | Name                               | string |\n",
    "| sex            | Sex                                | string |\n",
    "|                | Values: (female, male) | \n",
    "| age            | Age                                | number |\n",
    "| sibsp          | Number of Siblings/Spouses Aboard  | number |\n",
    "| parch          | Number of Parents/Children Aboard  | number |\n",
    "| ticket         | Ticket Number                      | string |\n",
    "| fare           | Passenger Fare                     | number |\n",
    "| cabin          | Cabin                              | string |\n",
    "|embarked        | Port of Embarkation                | character |\n",
    "|                | Values: (C = Cherbourg; Q = Queenstown; S = Southampton) |\n",
    "\n",
    "For example, in one function, we replace the text values for the 'Embarked' field with numbers. For example, the embarkation port labeled 'S' becomes 0, 'C' becomes 1, and 'Q' becomes 2.\n",
    "\n",
    "Later on in this notebook, we'll use the [scikit-learn package](http://scikit-learn.org) to create models for the data. Scikit-learn assumes that your data is all numbers-- *it can't read text*. So we need to substitute number assignments for the text fields. For example, for the sex field, we can replace the values 0 for females and 1 for males; or, we can have 34 for males and 123 for females (or -7.8 for males and 999.123 for females). The number doesn't matter so long as it is consistent-- males get one number and females get a different number. This should be done for an non-numeric field.\n",
    "\n",
    "We also have functions which replace the missing data (NaN) with the mean or median value within that data field. Sometimes we even drop fields if they have too many missing values or if they can't possibly be associated with the prediction. For example, the name of the person probably doesn't predict if they survived, but their age probably does."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "_cell_guid": "a2f45ec3-3fa6-9b35-7fd9-4ceeb6672846",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "'''\n",
    "This calls all of the preprocessing functions.\n",
    "Preprocessing should be done exactly the same on both the training and testing data sets.\n",
    "'''\n",
    "\n",
    "def preprocessData(df):\n",
    "    \n",
    "    # Convert the embarkation field from categorical (\"S\", \"C\", \"Q\")\n",
    "    # to numeric (0,1,2)\n",
    "    df = convertEmbarked(df)\n",
    "    \n",
    "    # Convert sex. Female = 0, Male = 1\n",
    "    df = convertSex(df)\n",
    "\n",
    "    df = addFamilyFactor(df)\n",
    "    \n",
    "    df = addTitles(df)\n",
    "\n",
    "    # Remove irrelevant and non-numeric columns (features)\n",
    "    df = df.drop(['Name', 'Cabin', 'PassengerId', 'Ticket'], axis=1) \n",
    "\n",
    "    # Replace the missing values (NaN) with the mean value for that field\n",
    "    df = replaceWithMean(df)\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "_cell_guid": "943e019d-99e0-3593-ae1a-e4367a454c82",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "'''\n",
    "Convert the sex field to numeric\n",
    "'''\n",
    "def convertSex(df):\n",
    "    \n",
    "    # Convert the 'male'/'female' strings to integer classifiers.\n",
    "    # Female = 0, Male = 1\n",
    "    # Create a new column called \"Gender\" which is a mapping of the \"Sex\" column into integer values\n",
    "    df[\"Gender\"] = df[\"Sex\"].map( {\"female\": 0, \"male\": 1} ).astype(int)\n",
    "    # Now drop the \"Sex\" column since we've already replaced it by the integer column \"Gender\"\n",
    "    df = df.drop(['Sex'], axis=1)\n",
    "    \n",
    "    return df\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "_cell_guid": "c264bc1d-48b3-7b61-a4fa-7a18f95fc5cc"
   },
   "outputs": [],
   "source": [
    "'''\n",
    "Scikit-learn can only handle numbers.\n",
    "So let's replace the text values for the 'Embarked' field with numbers. \n",
    "For example, the embarkation port labeled 'S' becomes 0, 'C' becomes 1, and 'Q' becomes 2.\n",
    "'''\n",
    "def convertEmbarked(df):\n",
    "    \n",
    "    if ('Embarked' in df.columns) :  # If the field 'Embarked' is in the pandas dataframe df\n",
    "        \n",
    "        # missing value, fill na with most often occured value\n",
    "        if (len(df[df[\"Embarked\"].isnull()]) > 0):\n",
    "\n",
    "            # We need to get rid of missing values (not-a-number, NaN)\n",
    "            # http://pandas.pydata.org/pandas-docs/stable/generated/pandas.DataFrame.mode.html\n",
    "            # If you want to impute missing values with the mode in a dataframe df, you can just do this:\n",
    "            df.loc[df[\"Embarked\"].isnull(), 'Embarked'] = df[\"Embarked\"].dropna().mode().iloc[0]\n",
    "\n",
    "        ports = list(enumerate(np.unique(df[\"Embarked\"])))  # Get the list of unique port IDs\n",
    "        port_dict = { name: i for i, name in ports } # Create a dictionary of the different port IDs\n",
    "        df[\"Embarked\"] = df[\"Embarked\"].map( lambda x: port_dict[x]).astype(int)  # Reassign the port IDs to numbers\n",
    "        \n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "873fe066-ddf3-3a32-2cd3-5b1efa1093d4"
   },
   "source": [
    "#### Titles\n",
    "The `Names` field of our data includes titles. So perhaps someone like _Duff Gordon, Lady. (Lucille Christiana Sutherland)_ will get a lifeboat before _Dooley, Mr. Patrick_ (apologies to Mr. Dooley). Of course, that's a guess, but it's probably a good one knowing a little bit about the tragic event. If that's the case, then let's parse the `Name` field for titles and add a new column called `Titles` which has a numeric value based on how important we think the person is."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "_cell_guid": "7e66a8ef-a0f7-c6f3-7dc9-45e152e418b8",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def addTitles(df):\n",
    "    \n",
    "    # we extract the title from each name\n",
    "    combined = df['Name'].map(lambda name:name.split(',')[1].split('.')[0].strip())\n",
    "    \n",
    "    # a map of more aggregated titles\n",
    "    Title_Dictionary = {\n",
    "                        \"Capt\":       1,\n",
    "                        \"Col\":        1,\n",
    "                        \"Major\":      1,\n",
    "                        \"Jonkheer\":   3,\n",
    "                        \"Don\":        3,\n",
    "                        \"Sir\" :       3,\n",
    "                        \"Dr\":         2,\n",
    "                        \"Rev\":        1,\n",
    "                        \"the Countess\":3,\n",
    "                        \"Dona\":       3,\n",
    "                        \"Mme\":        0,\n",
    "                        \"Mlle\":       0,\n",
    "                        \"Ms\":         0,\n",
    "                        \"Mr\" :        0,\n",
    "                        \"Mrs\" :       0,\n",
    "                        \"Miss\" :      0,\n",
    "                        \"Master\" :    1,\n",
    "                        \"Lady\" :      3\n",
    "\n",
    "                        }\n",
    "    \n",
    "    # we map each title\n",
    "    df['Title'] = combined.map(Title_Dictionary)\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "_cell_guid": "a912a187-7ea9-6578-381d-cc476194587c",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "'''\n",
    "Replace any missing values (NaN) with the mean value for that column\n",
    "'''\n",
    "def replaceWithMean(df):\n",
    "    \n",
    "    # Replace all NaNs in a Dataframe with the mean of that column (field).\n",
    "    # I think this only works for numbers (int, float) \n",
    "    # You should do this as the last step of pre-processing in case you want to replace the NaNs\n",
    "    # with some other method. Once you run this, all of the NaNs in the dataframe are gone.\n",
    "    df = df.fillna(df.mean())\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "_cell_guid": "17c4ec3b-0a45-cd20-af4e-14f1f94662d3",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "'''\n",
    "There are two \"family\" variables in the original data. This combines them both into one variable.\n",
    "'''\n",
    "def addFamilyFactor(df):\n",
    "    # Add a category called FamilyFactor\n",
    "    # Perhaps people with larger families had a greater probablity of rescue?\n",
    "    # If I just add the two together, then the new catgegory is just a linear transform and\n",
    "    # won't really add new info. So I add and then square the value. \n",
    "    df['FamilyFactor'] = np.power(df.SibSp + df.Parch, 2)\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "c42f8790-1337-6d41-721b-282b24276e29"
   },
   "source": [
    "### Read the training data\n",
    "The following cells read in the training data from the comma-separated data file `train.csv`. We're using pandas to store the data as an object because pandas is really good at data manipulation and many other libraries (numpy/scikit/matplotlib) work well with pandas objects."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "_cell_guid": "ea02ac49-ffb0-25b8-a82d-ef2c02f7e07f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 891 entries, 0 to 890\n",
      "Data columns (total 12 columns):\n",
      "PassengerId    891 non-null int64\n",
      "Survived       891 non-null int64\n",
      "Pclass         891 non-null int64\n",
      "Name           891 non-null object\n",
      "Sex            891 non-null object\n",
      "Age            714 non-null float64\n",
      "SibSp          891 non-null int64\n",
      "Parch          891 non-null int64\n",
      "Ticket         891 non-null object\n",
      "Fare           891 non-null float64\n",
      "Cabin          204 non-null object\n",
      "Embarked       889 non-null object\n",
      "dtypes: float64(2), int64(5), object(5)\n",
      "memory usage: 83.6+ KB\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "Read the training data from csv file\n",
    "'''\n",
    "train_df = pd.read_csv('../input/train.csv', header=0, dtype={\"Age\": np.float64})  # Load the train file into a dataframe\n",
    "\n",
    "# Get the basic info for the data in this file\n",
    "train_df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "3a7b41aa-dbff-3cc6-ddab-d66dfc4d1e4c"
   },
   "source": [
    "### Use Seaborn (matplotlib wrapper) to print pretty pictures of our raw data\n",
    "Here we show how to plot the raw data from the 'Embarked' variable. Note that if you embarked at 'C' (Cherbourg), then you had a better than 50% chance of surviving whereas the other two ports had less than 40% chance of surviving. It's not a huge correlation, but it might be helpful when combined with other features. So embarkation site might be a useful feature to use in our prediction model.\n",
    "\n",
    "You can try this approach on the other variables (e.g. sex, age) to see how they influence the survival rate. This is one method to select which features (i.e. fields/columns) you'll use in the final model.\n",
    "\n",
    "Remember, the [adaptive boosting](https://en.wikipedia.org/wiki/AdaBoost) method is good at taking weak classifiers and combining them (in a weighted way) to create strong prediction models. So many poorly-correlated variables might be as useful as a strongly-correlated one."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "_cell_guid": "13e54787-e7d3-4d19-e29d-8eae38664a51"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.text.Text at 0x7fe8064dce10>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA3wAAAFUCAYAAAB/dD5QAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fe809591f60>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Setup a plot with 3 subplots side by side\n",
    "fig, (axis1,axis2,axis3) = plt.subplots(1,3,figsize=(15,5))\n",
    "\n",
    "# Count plot of how many people embarked at each location\n",
    "# countplot is for categorial data, barplot for quantitative data\n",
    "sns.countplot(x=\"Embarked\", data=train_df, ax=axis1)\n",
    "axis1.set_title(\"# passengers per embarkation site\")\n",
    "\n",
    "# Comparing survivors versus fatalities as a function of embarkation\n",
    "sns.countplot(x=\"Survived\", hue=\"Embarked\", data=train_df, order=[1,0], ax=axis2)\n",
    "axis2.set_title(\"Survivors versus Fatalities\")\n",
    "\n",
    "# group by embarked, and get the mean for survived passengers for each value in Embarked\n",
    "embark_perc = train_df[[\"Embarked\", \"Survived\"]].groupby(['Embarked'],as_index=False).mean()\n",
    "sns.barplot(x='Embarked', y='Survived', data=embark_perc,order=['S','C','Q'],ax=axis3)\n",
    "axis3.set_title(\"Survival versus embarkation\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "cc4c57be-ea9a-be8a-7ffa-d5b50e47d447"
   },
   "source": [
    "### Pre-process the data\n",
    "We need to do something with the missing values, text strings, and irrelevant fields."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "_cell_guid": "38b078be-f217-4060-3b0e-836f19296b5b"
   },
   "outputs": [],
   "source": [
    "train_df = preprocessData(train_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "_cell_guid": "519552bf-3f2a-bb24-0f46-2ee56addf3e8"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Embarked</th>\n",
       "      <th>Gender</th>\n",
       "      <th>FamilyFactor</th>\n",
       "      <th>Title</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>891.000000</td>\n",
       "      <td>891.000000</td>\n",
       "      <td>891.000000</td>\n",
       "      <td>891.000000</td>\n",
       "      <td>891.000000</td>\n",
       "      <td>891.000000</td>\n",
       "      <td>891.000000</td>\n",
       "      <td>891.000000</td>\n",
       "      <td>891.000000</td>\n",
       "      <td>891.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.383838</td>\n",
       "      <td>2.308642</td>\n",
       "      <td>29.699118</td>\n",
       "      <td>0.523008</td>\n",
       "      <td>0.381594</td>\n",
       "      <td>32.204208</td>\n",
       "      <td>1.536476</td>\n",
       "      <td>0.647587</td>\n",
       "      <td>3.418631</td>\n",
       "      <td>0.089787</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.486592</td>\n",
       "      <td>0.836071</td>\n",
       "      <td>13.002015</td>\n",
       "      <td>1.102743</td>\n",
       "      <td>0.806057</td>\n",
       "      <td>49.693429</td>\n",
       "      <td>0.791503</td>\n",
       "      <td>0.477990</td>\n",
       "      <td>11.181689</td>\n",
       "      <td>0.362291</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.420000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>22.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>7.910400</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>29.699118</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>14.454200</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>35.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>31.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>80.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>512.329200</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>3.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Survived      Pclass         Age       SibSp       Parch        Fare  \\\n",
       "count  891.000000  891.000000  891.000000  891.000000  891.000000  891.000000   \n",
       "mean     0.383838    2.308642   29.699118    0.523008    0.381594   32.204208   \n",
       "std      0.486592    0.836071   13.002015    1.102743    0.806057   49.693429   \n",
       "min      0.000000    1.000000    0.420000    0.000000    0.000000    0.000000   \n",
       "25%      0.000000    2.000000   22.000000    0.000000    0.000000    7.910400   \n",
       "50%      0.000000    3.000000   29.699118    0.000000    0.000000   14.454200   \n",
       "75%      1.000000    3.000000   35.000000    1.000000    0.000000   31.000000   \n",
       "max      1.000000    3.000000   80.000000    8.000000    6.000000  512.329200   \n",
       "\n",
       "         Embarked      Gender  FamilyFactor       Title  \n",
       "count  891.000000  891.000000    891.000000  891.000000  \n",
       "mean     1.536476    0.647587      3.418631    0.089787  \n",
       "std      0.791503    0.477990     11.181689    0.362291  \n",
       "min      0.000000    0.000000      0.000000    0.000000  \n",
       "25%      1.000000    0.000000      0.000000    0.000000  \n",
       "50%      2.000000    1.000000      0.000000    0.000000  \n",
       "75%      2.000000    1.000000      1.000000    0.000000  \n",
       "max      2.000000    1.000000    100.000000    3.000000  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "bbf4380d-6c98-00ae-6d04-0412cd242b67"
   },
   "source": [
    "# [AdaBoost (Adaptive Boost)](https://en.wikipedia.org/wiki/AdaBoost)\n",
    "## It's modeling time.\n",
    "Let's create an AdaBoost classifier to model the training data. Adaboost is a meta-algorithm for machine learning. So it's not an actual machine learning model, but rather a way to combine machine learning models. AdaBoost takes an ensemble other machine learning classifiers (e.g. regression, b-trees, random forests, neural networks) and combines them in a weighted fashion to create a new classifier. So it is like taking several weak predictive models and combining them to form one super model.\n",
    "\n",
    "For example, let's say we have 5 neural networks that predict a binary output (0 or 1). So each of the 5 neural nets produce a prediction for us but each is set up in a different way (different layers, different inputs, etc). But, let's say that none of these neural networks are really good predictors. Adaboost is a way to combine all 5 neural networks into a single model that gives a better prediction than any one model alone (the sum is greater than the parts).\n",
    "\n",
    "For binary classifiers, an error rate of 50% is just like flipping a coin-- it's the worse you can do since it is completely random (if you are worse than 50%, then you should just guess the opposite of whatever the model predicts!). Any model that has an error rate close to 50% (e.g. 43%) is considered a \"weak\" predictive model. Any model that is close to a 0% prediction error (e.g. 9%) is considered a \"strong\" predictive model.\n",
    "\n",
    "AdaBoost takes our 5 \"weak\" neural networks, multiplies their output (0-1) by some scaling factor, adds the result, and then determines if that is above a certain threshold. So it's a linear summation of each individual model. It's sort of like the \"Poll the Audience\" lifeline in \"Who Wants to Be a Millionaire?\" Every model gets a vote and the votes are tallied to give a prediction. However, in AdaBoost, each vote is weighted depending on the strength of the voter (i.e. the individual model). So one person might be smart, but a lot of semi-smart people can be geniuses if they work together to come up with an answer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "_cell_guid": "f897f95d-2cd7-d0c3-bff3-542873f22540"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training with model. Please WAIT ...\n",
      "Ok. Finished training the model.\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier, AdaBoostClassifier\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "# The data is now ready to go. So lets fit to the train, then predict to the test!\n",
    "# Convert back to a numpy array\n",
    "train_data = train_df.values\n",
    "train_features = train_data[0::,1::]   # The features to use for the prediction model (e.g. age, family size)\n",
    "train_result = train_data[0::,0]       # The thing the model predicts (i.e. survived)\n",
    "\n",
    "print('Training with model. Please WAIT ...')\n",
    "\n",
    "# Adaboost using a bunch of RandomForest models\n",
    "# SAMME  Stagewise Additive Modeling using a Multi-class Exponential loss function \n",
    "# Zhu, H. Zou, S. Rosset, T. Hastie, Multi-class AdaBoost, 2009.\n",
    "# For more info, http://scikit-learn.org/stable/auto_examples/ensemble/plot_adaboost_multiclass.html\n",
    "model = AdaBoostClassifier(RandomForestClassifier(n_estimators = 1000),\n",
    "                         algorithm=\"SAMME\",\n",
    "                         n_estimators=500)\n",
    "\n",
    "# Here's how to do a Random Forest\n",
    "#model = RandomForestClassifier(n_estimators=1000).fit(train_features, train_result)\n",
    "\n",
    "# Here's a support-vector machine model (SVM)\n",
    "#model = SVC(probability=True,random_state=1)\n",
    "\n",
    "# Fit the training data to the Adaboost model\n",
    "model = model.fit(train_features, train_result)\n",
    "\n",
    "print ('Ok. Finished training the model.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "f67be0c3-4bb3-a5a8-a3f5-de0c32210e3e"
   },
   "source": [
    "### Accuracy\n",
    "So how good is this model? Well, compute how well our predictions matched with the known values. This is called accuracy (or conversely error)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "_cell_guid": "b8fa3002-c9ef-8bb7-3889-a91296bea4d1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy = 98.43%\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "print ('Accuracy = {:0.2f}%'.format(100.0 * accuracy_score(train_result, model.predict(train_features))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "4160b8c1-d96c-4dab-d375-38e27fcf83f1"
   },
   "source": [
    "### Cross-validation\n",
    "Your accuracy shows that got a *really* good model, right?\n",
    "\n",
    "Well, not so fast.\n",
    "\n",
    "Accuracy is really deceptive. Remember, you are fitting the curve to the data. You expect a good fit to that data. Sometimes, you can fit the data so well that the model only really works on that specific data set. This is called _overfitting_. So to really test the true accuracy of your brand new model, you need to test the model on new data (i.e. data you didn't train the model on).\n",
    "\n",
    "[Cross validation](http://scikit-learn.org/stable/modules/cross_validation.html) gives you an idea of how good the model predicts new data. The scikit-learn module `model_selection` has a function called `cross_val_score` which returns the accuracy of the model. It does this by randomly splitting your data into two sets (aka k-folds). One set will be used to train the model. The other set will be used to test how accurate that model is. This helps us identify overfitting. Many models can perfectly fit the dataset during training, but be so specific to that dataset that they fail when they see new data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "_cell_guid": "d81deb3a-e71a-e5e0-ab4e-8a45e69d00a7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating cross-validation of the training model. Please WAIT ...\n",
      "On average, this model is correct 80.70% (+/- 4.96%) of the time.\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "# Calculating cross-validation of the training model\n",
    "print ('Calculating cross-validation of the training model. Please WAIT ...')\n",
    "\n",
    "# Cross-validation with k-fold of 5. So this will randomly split the training data into two sets.\n",
    "# It then fits a model to one set and tests it against the other to get an accuracy.\n",
    "# It will do this 5 times and return the average accuracy.\n",
    "scores = cross_val_score(model, train_features, train_result, cv=5)\n",
    "print ( 'On average, this model is correct {:0.2f}% (+/- {:0.2f}%) of the time.'.format(\n",
    "        scores.mean() * 100.0, scores.std() * 2 * 100.0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "80768070-b409-354a-0cd2-54f262944ba6"
   },
   "source": [
    "### How'd you do?\n",
    "Was the cross-validation disappointing? Did the cross-validation accuracy fall? It typically does. This is the science part of data science. To get better accuracy and better predictions, you need to:\n",
    "\n",
    "1. work with the feature set - Do all of your features help in the prediction? Are their transformations in those features which will make them work even better.\n",
    "\n",
    "2. try out new models - Is SVM more appropriate? Neural nets? Random forests? Little bubbly bears?\n",
    "\n",
    "This is where Jupyter shines. You can keep playing with the dataset and the model until you get your best result. And, you can document your process along the way."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "18dc30d5-4e2c-ab9b-a89b-013de25ac957"
   },
   "source": [
    "### Get the testing data\n",
    "Now read in the test data. That's the data where we don't know the result (i.e. no 'Survived' field). We'll use the trained model on that data to predict the value and send that to Kaggle."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "_cell_guid": "b86cdf40-7b0d-ddf9-e678-a649946b69fa"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 418 entries, 0 to 417\n",
      "Data columns (total 11 columns):\n",
      "PassengerId    418 non-null int64\n",
      "Pclass         418 non-null int64\n",
      "Name           418 non-null object\n",
      "Sex            418 non-null object\n",
      "Age            332 non-null float64\n",
      "SibSp          418 non-null int64\n",
      "Parch          418 non-null int64\n",
      "Ticket         418 non-null object\n",
      "Fare           417 non-null float64\n",
      "Cabin          91 non-null object\n",
      "Embarked       418 non-null object\n",
      "dtypes: float64(2), int64(4), object(5)\n",
      "memory usage: 36.0+ KB\n"
     ]
    }
   ],
   "source": [
    "# Import the test data into a Pandas dataframe\n",
    "test_df = pd.read_csv('../input/test.csv', header=0, dtype={\"Age\": np.float64})        # Load the test file into a dataframe\n",
    "\n",
    "test_df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "9b5be18c-cba8-8571-644f-337af88a50f3"
   },
   "source": [
    "### Pre-processing\n",
    "I need to preprocess this data exactly like I pre-processed the training set data. If I don't, then the model won't work correctly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "_cell_guid": "660f72f8-c956-7324-e729-f06578ea3b7b"
   },
   "outputs": [],
   "source": [
    "# Grab the passenger Ids first since they are removed by the pre-processing function\n",
    "testIds = test_df['PassengerId']\n",
    "\n",
    "test_df = preprocessData(test_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "0564e327-ed8c-4830-254e-236c2bd9537d"
   },
   "source": [
    "### Prediction Time\n",
    "\n",
    "Now use the Testing data and predict the output (survived) based on the model we've created from the training data. Amazingly, this just takes one line. Scikit-learn does the rest for you."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "_cell_guid": "f0abaa83-c74a-36f0-5b94-0f167a671421"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting the survival from the test data. PLEASE WAIT... DONE\n"
     ]
    }
   ],
   "source": [
    "print('Predicting the survival from the test data. PLEASE WAIT... ', end='') # Supress newline with end=''\n",
    "\n",
    "test_predictions = model.predict(test_df.values)\n",
    "\n",
    "print('DONE')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "55b1a71b-2ccd-facd-cb0a-ed9755a48042"
   },
   "source": [
    "## Send the predictions to [Kaggle](https://www.kaggle.com/c/titanic)\n",
    "Now that we have the model's predictions on the test data, let's save it in a comma-separated value (csv) file for uploading to [Kaggle](https://www.kaggle.com/c/titanic)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "_cell_guid": "9f2c137e-e26e-222e-151e-232d2fed1800"
   },
   "outputs": [],
   "source": [
    "# Create a new dataframe with only the columns Kaggle wants from the dataset.\n",
    "submission = pd.DataFrame({\"PassengerId\" : testIds.astype(int),\n",
    "                           \"Survived\" : test_predictions.astype(int)})\n",
    "\n",
    "# Save the submission to CSV file\n",
    "submission.to_csv(\"titanic_submission\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "9062df68-f439-6ddb-5f9b-50be27cd889a",
    "collapsed": true
   },
   "source": [
    "## You're done.\n",
    "Now you just need to upload the file `titanic_submission` to Kaggle and see how you do. \n",
    "\n",
    "A very simple prediction model can usually score with about a 70-80% accuracy. By playing around with models and features, you can bump that performance up to about 90%."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "_cell_guid": "c31d3373-f041-9870-911b-130fcb12222b",
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "_change_revision": 15,
  "_is_fork": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
